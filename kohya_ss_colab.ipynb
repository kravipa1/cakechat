{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kravipa1/cakechat/blob/master/kohya_ss_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NrgcDwZxgDOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dca37f0c-72df-4e81-8663-6cb7366fa60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: dadaptation==3.1 in /usr/local/lib/python3.11/dist-packages (3.1)\n",
            "Requirement already satisfied: diffusers==0.17.1 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.17.1) (0.17.1)\n",
            "Requirement already satisfied: easygui==0.98.3 in /usr/local/lib/python3.11/dist-packages (0.98.3)\n",
            "Requirement already satisfied: einops==0.6.0 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: fairscale==0.4.13 in /usr/local/lib/python3.11/dist-packages (0.4.13)\n",
            "Requirement already satisfied: ftfy==6.1.1 in /usr/local/lib/python3.11/dist-packages (6.1.1)\n",
            "Requirement already satisfied: gradio==3.36.1 in /usr/local/lib/python3.11/dist-packages (3.36.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (0.16.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (8.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (1.24.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.17.1->diffusers[torch]==0.17.1) (2.32.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from fairscale==0.4.13) (2.0.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.1.1) (0.2.13)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (24.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (3.11.15)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.116.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.6.0)\n",
            "Requirement already satisfied: gradio-client>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (1.10.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.28.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (3.1.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.36.1) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (3.10.0)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.3.3)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (3.10.18)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (2.2.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.25.1)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (2.19.2)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.0.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (6.0.2)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (0.35.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio==3.36.1) (15.0.1)\n",
            "Requirement already satisfied: accelerate>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.17.1) (0.21.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.17.1) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.17.1) (7.0.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair>=4.2.0->gradio==3.36.1) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair>=4.2.0->gradio==3.36.1) (1.46.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from altair>=4.2.0->gradio==3.36.1) (4.14.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client>=0.2.7->gradio==3.36.1) (2025.5.1)\n",
            "Collecting huggingface-hub>=0.13.2 (from diffusers==0.17.1->diffusers[torch]==0.17.1)\n",
            "  Using cached huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.36.1) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.36.1) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.36.1) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->gradio==3.36.1) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->gradio==3.36.1) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.1->diffusers[torch]==0.17.1) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.1->diffusers[torch]==0.17.1) (1.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.36.1) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.36.1) (2.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->fairscale==0.4.13) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->fairscale==0.4.13) (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->fairscale==0.4.13) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.8.0->fairscale==0.4.13) (4.0.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.8.0->fairscale==0.4.13) (18.1.8)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.14.0->gradio==3.36.1) (8.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->gradio==3.36.1) (1.20.1)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==3.36.1) (0.46.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->gradio==3.36.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->gradio==3.36.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->gradio==3.36.1) (0.4.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.17.1->diffusers[torch]==0.17.1) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.36.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.36.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.36.1) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.36.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.36.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gradio==3.36.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gradio==3.36.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gradio==3.36.1) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.17.1->diffusers[torch]==0.17.1) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.17.1->diffusers[torch]==0.17.1) (2.5.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.36.1) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.36.1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.36.1) (0.26.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.36.1) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->gradio==3.36.1) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->gradio==3.36.1) (1.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8.0->fairscale==0.4.13) (1.3.0)\n",
            "Using cached huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.16.4\n",
            "    Uninstalling huggingface-hub-0.16.4:\n",
            "      Successfully uninstalled huggingface-hub-0.16.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.33.4\n",
            "Requirement already satisfied: lion-pytorch==0.0.6 in /usr/local/lib/python3.11/dist-packages (0.0.6)\n",
            "Requirement already satisfied: lycoris_lora==1.8.0.dev6 in /usr/local/lib/python3.11/dist-packages (1.8.0.dev6)\n",
            "Requirement already satisfied: open-clip-torch==2.20.0 in /usr/local/lib/python3.11/dist-packages (2.20.0)\n",
            "Requirement already satisfied: prodigyopt==1.0 in /usr/local/lib/python3.11/dist-packages (1.0)\n",
            "Requirement already satisfied: pytorch-lightning==1.9.0 in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: safetensors==0.3.1 in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
            "Requirement already satisfied: timm==0.6.12 in /usr/local/lib/python3.11/dist-packages (0.6.12)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from lion-pytorch==0.0.6) (2.0.1)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from lycoris_lora==1.8.0.dev6) (0.17.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from lycoris_lora==1.8.0.dev6) (4.30.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (0.15.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (6.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (0.33.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.11/dist-packages (from open-clip-torch==2.20.0) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (1.24.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2025.5.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (1.7.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (4.14.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.4.2->pytorch-lightning==1.9.0) (80.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->lion-pytorch==0.0.6) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6->lion-pytorch==0.0.6) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.6->lion-pytorch==0.0.6) (4.0.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.6->lion-pytorch==0.0.6) (18.1.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers->lycoris_lora==1.8.0.dev6) (11.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->lycoris_lora==1.8.0.dev6) (8.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers->lycoris_lora==1.8.0.dev6) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch==2.20.0) (1.1.5)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch==2.20.0) (0.2.13)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers->lycoris_lora==1.8.0.dev6) (0.13.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.20.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->lycoris_lora==1.8.0.dev6) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->lion-pytorch==0.0.6) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->lycoris_lora==1.8.0.dev6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->lycoris_lora==1.8.0.dev6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->lycoris_lora==1.8.0.dev6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->lycoris_lora==1.8.0.dev6) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.6->lion-pytorch==0.0.6) (1.3.0)\n",
            "Requirement already satisfied: tk==0.1.0 in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: transformers==4.30.2 in /usr/local/lib/python3.11/dist-packages (4.30.2)\n",
            "Requirement already satisfied: voluptuous==0.13.1 in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: wandb==0.15.0 in /usr/local/lib/python3.11/dist-packages (0.15.0)\n",
            "Requirement already satisfied: xformers==0.0.20 in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Collecting torchvision==0.15.2\n",
            "  Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting huggingface_hub==0.16.4\n",
            "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting accelerate==0.21.0\n",
            "  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting requests (from torchvision==0.15.2)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting torch==2.0.1 (from torchvision==0.15.2)\n",
            "  Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.15.2)\n",
            "  Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from huggingface_hub==0.16.4)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from huggingface_hub==0.16.4)\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface_hub==0.16.4)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pyyaml>=5.1 (from huggingface_hub==0.16.4)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub==0.16.4)\n",
            "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging>=20.9 (from huggingface_hub==0.16.4)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting psutil (from accelerate==0.21.0)\n",
            "  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting sympy (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.15.2)\n",
            "  Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.2)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.2)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.2)\n",
            "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1->torchvision==0.15.2)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "Using cached accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "Using cached lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: mpmath, lit, wheel, urllib3, typing-extensions, tqdm, sympy, setuptools, pyyaml, psutil, pillow, packaging, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, MarkupSafe, idna, fsspec, filelock, cmake, charset_normalizer, certifi, requests, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface_hub, triton, torch, torchvision, accelerate\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: lit\n",
            "    Found existing installation: lit 18.1.8\n",
            "    Uninstalling lit-18.1.8:\n",
            "      Successfully uninstalled lit-18.1.8\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 80.9.0\n",
            "    Uninstalling setuptools-80.9.0:\n",
            "      Successfully uninstalled setuptools-80.9.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 7.0.0\n",
            "    Uninstalling psutil-7.0.0:\n",
            "      Successfully uninstalled psutil-7.0.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nccl-cu11\n",
            "    Found existing installation: nvidia-nccl-cu11 2.14.3\n",
            "    Uninstalling nvidia-nccl-cu11-2.14.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu11-2.14.3\n",
            "  Attempting uninstall: nvidia-cufft-cu11\n",
            "    Found existing installation: nvidia-cufft-cu11 10.9.0.58\n",
            "    Uninstalling nvidia-cufft-cu11-10.9.0.58:\n",
            "      Successfully uninstalled nvidia-cufft-cu11-10.9.0.58\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.7.99\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.1\n",
            "    Uninstalling fsspec-2025.5.1:\n",
            "      Successfully uninstalled fsspec-2025.5.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 4.0.3\n",
            "    Uninstalling cmake-4.0.3:\n",
            "      Successfully uninstalled cmake-4.0.3\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.7.14\n",
            "    Uninstalling certifi-2025.7.14:\n",
            "      Successfully uninstalled certifi-2025.7.14\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: nvidia-nvtx-cu11\n",
            "    Found existing installation: nvidia-nvtx-cu11 11.7.91\n",
            "    Uninstalling nvidia-nvtx-cu11-11.7.91:\n",
            "      Successfully uninstalled nvidia-nvtx-cu11-11.7.91\n",
            "  Attempting uninstall: nvidia-cusparse-cu11\n",
            "    Found existing installation: nvidia-cusparse-cu11 11.7.4.91\n",
            "    Uninstalling nvidia-cusparse-cu11-11.7.4.91:\n",
            "      Successfully uninstalled nvidia-cusparse-cu11-11.7.4.91\n",
            "  Attempting uninstall: nvidia-curand-cu11\n",
            "    Found existing installation: nvidia-curand-cu11 10.2.10.91\n",
            "    Uninstalling nvidia-curand-cu11-10.2.10.91:\n",
            "      Successfully uninstalled nvidia-curand-cu11-10.2.10.91\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.7.99\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "    Found existing installation: nvidia-cuda-cupti-cu11 11.7.101\n",
            "    Uninstalling nvidia-cuda-cupti-cu11-11.7.101:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.7.101\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.10.3.66\n",
            "    Uninstalling nvidia-cublas-cu11-11.10.3.66:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu11\n",
            "    Found existing installation: nvidia-cusolver-cu11 11.4.0.1\n",
            "    Uninstalling nvidia-cusolver-cu11-11.4.0.1:\n",
            "      Successfully uninstalled nvidia-cusolver-cu11-11.4.0.1\n",
            "  Attempting uninstall: nvidia-cudnn-cu11\n",
            "    Found existing installation: nvidia-cudnn-cu11 8.5.0.96\n",
            "    Uninstalling nvidia-cudnn-cu11-8.5.0.96:\n",
            "      Successfully uninstalled nvidia-cudnn-cu11-8.5.0.96\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.33.4\n",
            "    Uninstalling huggingface-hub-0.33.4:\n",
            "      Successfully uninstalled huggingface-hub-0.33.4\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2\n",
            "    Uninstalling torchvision-0.15.2:\n",
            "      Successfully uninstalled torchvision-0.15.2\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.21.0\n",
            "    Uninstalling accelerate-0.21.0:\n",
            "      Successfully uninstalled accelerate-0.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires flax>=0.2.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jaxlib>=0.1.51, which is not installed.\n",
            "orbax-checkpoint 0.11.16 requires jax>=0.5.0, which is not installed.\n",
            "chex 0.1.89 requires jax>=0.4.27, which is not installed.\n",
            "chex 0.1.89 requires jaxlib>=0.4.27, which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "gradio-client 1.10.1 requires huggingface-hub>=0.19.3, but you have huggingface-hub 0.16.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "peft 0.16.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.16.4 which is incompatible.\n",
            "langchain-core 0.3.68 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.16.4 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 accelerate-0.21.0 certifi-2025.7.14 charset_normalizer-3.4.2 cmake-4.0.3 filelock-3.18.0 fsspec-2025.5.1 huggingface_hub-0.16.4 idna-3.10 jinja2-3.1.6 lit-18.1.8 mpmath-1.3.0 networkx-3.5 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 packaging-25.0 pillow-11.3.0 psutil-7.0.0 pyyaml-6.0.2 requests-2.32.4 setuptools-80.9.0 sympy-1.14.0 torch-2.0.1 torchvision-0.15.2 tqdm-4.67.1 triton-2.0.0 typing-extensions-4.14.1 urllib3-2.5.0 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "numpy",
                  "packaging",
                  "pkg_resources",
                  "psutil"
                ]
              },
              "id": "b6186ec84e29450e81d70d4dee343a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping jax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping jaxlib as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping flax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping optax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping orbax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m/content\n",
            "Requirement already satisfied: bitsandbytes==0.41.1 in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "/content\n",
            "fatal: destination path 'kohya_ss' already exists and is not an empty directory.\n",
            "/content/kohya_ss\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/routes.py:26: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "/usr/local/lib/python3.11/dist-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n",
            "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
            "/usr/local/lib/python3.11/dist-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n",
            "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
            "\u001b[2;36m17:20:13-939143\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m headless: \u001b[3;92mTrue\u001b[0m                                         \n",
            "\u001b[2;36m17:20:13-942377\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Load CSS\u001b[33m...\u001b[0m                                            \n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://b86fdf4e570a28a54b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\u001b[2;36m17:22:59-493324\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Start training LoRA Standard \u001b[33m...\u001b[0m                       \n",
            "\u001b[2;36m17:22:59-501174\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Valid image folder names found in:                     \n",
            "\u001b[2;36m                \u001b[0m         \u001b[35m/content/drive/MyDrive/Angelica/\u001b[0m\u001b[95mImages\u001b[0m                 \n",
            "\u001b[2;36m17:22:59-507531\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Headless mode, skipping verification if model already  \n",
            "\u001b[2;36m                \u001b[0m         exist\u001b[33m...\u001b[0m if model already exist it will be             \n",
            "\u001b[2;36m                \u001b[0m         overwritten\u001b[33m...\u001b[0m                                         \n",
            "\u001b[2;36m17:22:59-514326\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Folder 001_Angelica: \u001b[1;36m31\u001b[0m images found                   \n",
            "\u001b[2;36m17:22:59-515748\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Folder 001_Angelica: \u001b[1;36m31\u001b[0m steps                          \n",
            "\u001b[2;36m17:22:59-516925\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Total steps: \u001b[1;36m31\u001b[0m                                        \n",
            "\u001b[2;36m17:22:59-518073\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Train batch size: \u001b[1;36m1\u001b[0m                                    \n",
            "\u001b[2;36m17:22:59-519181\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Gradient accumulation steps: \u001b[1;36m1.0\u001b[0m                       \n",
            "\u001b[2;36m17:22:59-520314\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Epoch: \u001b[1;36m10\u001b[0m                                              \n",
            "\u001b[2;36m17:22:59-521385\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Regulatization factor: \u001b[1;36m1\u001b[0m                               \n",
            "\u001b[2;36m17:22:59-522519\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m max_train_steps \u001b[1m(\u001b[0m\u001b[1;36m31\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m1\u001b[0m \u001b[35m/\u001b[0m \u001b[1;36m1.0\u001b[0m * \u001b[1;36m10\u001b[0m * \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m = \u001b[1;36m310\u001b[0m          \n",
            "\u001b[2;36m17:22:59-523951\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m stop_text_encoder_training = \u001b[1;36m0\u001b[0m                         \n",
            "\u001b[2;36m17:22:59-525093\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m lr_warmup_steps = \u001b[1;36m31\u001b[0m                                   \n",
            "\u001b[2;36m17:22:59-531688\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Saving training config to                              \n",
            "\u001b[2;36m                \u001b[0m         \u001b[35m/content/drive/MyDrive/Angelica/Logs/\u001b[0m\u001b[95mlast_20250714-1722\u001b[0m\n",
            "\u001b[2;36m                \u001b[0m         \u001b[95m59.json...\u001b[0m                                             \n",
            "\u001b[2;36m17:22:59-539876\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m accelerate launch --\u001b[33mnum_cpu_threads_per_process\u001b[0m=\u001b[1;36m2\u001b[0m      \n",
            "\u001b[2;36m                \u001b[0m         \u001b[32m\"./train_network.py\"\u001b[0m --enable_bucket                   \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mpretrained_model_name_or_path\u001b[0m=\u001b[32m\"runwayml\u001b[0m\u001b[32m/stable-diffus\u001b[0m\n",
            "\u001b[2;36m                \u001b[0m         \u001b[32mion-v1-5\"\u001b[0m                                              \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mtrain_data_dir\u001b[0m=\u001b[32m\"/content/drive/MyDrive/Angelica/Image\u001b[0m\n",
            "\u001b[2;36m                \u001b[0m         \u001b[32ms\"\u001b[0m --\u001b[33mresolution\u001b[0m=\u001b[32m\"512\u001b[0m\u001b[32m,512\"\u001b[0m                              \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33moutput_dir\u001b[0m=\u001b[32m\"/content/drive/MyDrive/Angelica/Logs\"\u001b[0m    \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mlogging_dir\u001b[0m=\u001b[32m\"/content/drive/MyDrive/Angelica/Logs\"\u001b[0m   \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mnetwork_alpha\u001b[0m=\u001b[32m\"16\"\u001b[0m --\u001b[33msave_model_as\u001b[0m=\u001b[35msafetensors\u001b[0m       \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mnetwork_module\u001b[0m=\u001b[35mnetworks\u001b[0m.lora --\u001b[33mtext_encoder_lr\u001b[0m=\u001b[1;36m5e\u001b[0m\u001b[1;36m-05\u001b[0m \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33munet_lr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0001\u001b[0m --\u001b[33mnetwork_dim\u001b[0m=\u001b[1;36m16\u001b[0m --\u001b[33moutput_name\u001b[0m=\u001b[32m\"last\"\u001b[0m \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mlr_scheduler_num_cycles\u001b[0m=\u001b[32m\"10\"\u001b[0m --no_half_vae           \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mlearning_rate\u001b[0m=\u001b[32m\"0\u001b[0m\u001b[32m.0001\"\u001b[0m --\u001b[33mlr_scheduler\u001b[0m=\u001b[32m\"cosine\"\u001b[0m       \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mlr_warmup_steps\u001b[0m=\u001b[32m\"31\"\u001b[0m --\u001b[33mtrain_batch_size\u001b[0m=\u001b[32m\"1\"\u001b[0m          \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mmax_train_steps\u001b[0m=\u001b[32m\"310\"\u001b[0m --\u001b[33msave_every_n_epochs\u001b[0m=\u001b[32m\"1\"\u001b[0m      \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mmixed_precision\u001b[0m=\u001b[32m\"fp16\"\u001b[0m --\u001b[33msave_precision\u001b[0m=\u001b[32m\"fp16\"\u001b[0m       \n",
            "\u001b[2;36m                \u001b[0m         --cache_latents --\u001b[33moptimizer_type\u001b[0m=\u001b[32m\"AdamW8bit\"\u001b[0m           \n",
            "\u001b[2;36m                \u001b[0m         --\u001b[33mmax_data_loader_n_workers\u001b[0m=\u001b[32m\"0\"\u001b[0m --\u001b[33mbucket_reso_steps\u001b[0m=\u001b[1;36m64\u001b[0m \n",
            "\u001b[2;36m                \u001b[0m         --shuffle_caption --xformers --bucket_no_upscale       \n",
            "2025-07-14 17:23:06.118961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752513786.385630   37471 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752513786.458865   37471 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-14 17:23:07.029189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/wandb/apis/public.py:3109: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2025-07-14 17:23:16.539938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752513796.559731   37548 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752513796.565662   37548 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-14 17:23:16.584878: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/wandb/apis/public.py:3109: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n",
            "prepare tokenizer\n",
            "Downloading vocab.json: 961kB [00:00, 68.7MB/s]\n",
            "Downloading merges.txt: 525kB [00:00, 127MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 2.71MB/s]\n",
            "Downloading tokenizer_config.json: 100% 905/905 [00:00<00:00, 5.35MB/s]\n",
            "Using DreamBooth method.\n",
            "prepare images.\n",
            "found directory /content/drive/MyDrive/Angelica/Images/001_Angelica contains 31 image files\n",
            "No caption file found for 31 images. Training will continue without captions for these images. If class token exists, it will be used. / 31枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。\n",
            "/content/drive/MyDrive/Angelica/Images/001_Angelica/img-01.png\n",
            "/content/drive/MyDrive/Angelica/Images/001_Angelica/img-010.png\n",
            "/content/drive/MyDrive/Angelica/Images/001_Angelica/img-011.png\n",
            "/content/drive/MyDrive/Angelica/Images/001_Angelica/img-012.png\n",
            "/content/drive/MyDrive/Angelica/Images/001_Angelica/img-013.png\n",
            "/content/drive/MyDrive/Angelica/Images/001_Angelica/img-014.png... and 26 more\n",
            "31 train images with repeating.\n",
            "0 reg images.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (512, 512)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: 256\n",
            "  max_bucket_reso: 1024\n",
            "  bucket_reso_steps: 64\n",
            "  bucket_no_upscale: True\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/drive/MyDrive/Angelica/Images/001_Angelica\"\n",
            "    image_count: 31\n",
            "    num_repeats: 1\n",
            "    shuffle_caption: True\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    is_reg: False\n",
            "    class_tokens: Angelica\n",
            "    caption_extension: .caption\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 31/31 [00:23<00:00,  1.30it/s]\n",
            "make buckets\n",
            "min_bucket_reso and max_bucket_reso are ignored if bucket_no_upscale is set, because bucket reso is defined by image size automatically / bucket_no_upscaleが指定された場合は、bucketの解像度は画像サイズから自動計算されるため、min_bucket_resoとmax_bucket_resoは無視されます\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (384, 576), count: 30\n",
            "bucket 1: resolution (512, 512), count: 1\n",
            "mean ar error (without repeats): 0.0\n",
            "preparing accelerator\n",
            "loading model for process 0/1\n",
            "load Diffusers pretrained models: runwayml/stable-diffusion-v1-5\n",
            "Downloading model_index.json: 100% 541/541 [00:00<00:00, 2.99MB/s]\n",
            "Fetching 9 files:   0% 0/9 [00:00<?, ?it/s]\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 2.17MB/s]\n",
            "Fetching 9 files:  11% 1/9 [00:00<00:03,  2.20it/s]\n",
            "Downloading config.json: 100% 743/743 [00:00<00:00, 3.46MB/s]\n",
            "\n",
            "Downloading scheduler_config.json: 100% 308/308 [00:00<00:00, 1.95MB/s]\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading config.json: 100% 617/617 [00:00<00:00, 4.44MB/s]\n",
            "\n",
            "\n",
            "Downloading model.safetensors:   0% 0.00/492M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading config.json: 100% 547/547 [00:00<00:00, 2.32MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   0% 10.5M/3.44G [00:00<00:44, 76.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   3% 10.5M/335M [00:00<00:03, 86.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   2% 10.5M/492M [00:00<00:06, 73.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   4% 21.0M/492M [00:00<00:05, 82.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:   6% 21.0M/335M [00:00<00:03, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   1% 31.5M/3.44G [00:00<00:38, 88.3MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:   9% 41.9M/492M [00:00<00:04, 90.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   1% 41.9M/3.44G [00:00<00:41, 81.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  13% 41.9M/335M [00:00<00:03, 84.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   2% 52.4M/3.44G [00:00<00:40, 83.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  16% 52.4M/335M [00:00<00:03, 77.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  11% 52.4M/492M [00:00<00:06, 73.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   2% 62.9M/3.44G [00:00<00:41, 80.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  19% 62.9M/335M [00:00<00:03, 79.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  15% 73.4M/492M [00:00<00:04, 90.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  22% 73.4M/335M [00:00<00:03, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   2% 83.9M/3.44G [00:00<00:37, 88.4MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  17% 83.9M/492M [00:01<00:04, 83.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   3% 94.4M/3.44G [00:01<00:40, 82.4MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  19% 94.4M/492M [00:01<00:04, 80.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  28% 94.4M/335M [00:01<00:02, 85.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   3% 105M/3.44G [00:01<00:39, 84.2MB/s] \u001b[A\n",
            "\n",
            "Downloading model.safetensors:  21% 105M/492M [00:01<00:04, 83.5MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  31% 105M/335M [00:01<00:02, 85.4MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   3% 115M/3.44G [00:01<00:38, 86.6MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  23% 115M/492M [00:01<00:04, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  34% 115M/335M [00:01<00:02, 75.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   4% 136M/3.44G [00:01<00:34, 95.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  38% 126M/335M [00:01<00:02, 80.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  28% 136M/492M [00:01<00:03, 95.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   4% 147M/3.44G [00:01<00:35, 93.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  41% 136M/335M [00:01<00:02, 79.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  32% 157M/492M [00:01<00:03, 108MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  44% 147M/335M [00:01<00:02, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  36% 178M/492M [00:01<00:02, 121MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   5% 168M/3.44G [00:01<00:34, 94.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  50% 168M/335M [00:01<00:01, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  40% 199M/492M [00:02<00:02, 122MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   5% 189M/3.44G [00:02<00:31, 103MB/s] \u001b[A\n",
            "\n",
            "Downloading model.safetensors:  45% 220M/492M [00:02<00:01, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  56% 189M/335M [00:02<00:01, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   6% 210M/3.44G [00:02<00:28, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  60% 199M/335M [00:02<00:01, 89.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  49% 241M/492M [00:02<00:02, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  63% 210M/335M [00:02<00:01, 91.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   7% 231M/3.44G [00:02<00:33, 96.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  66% 220M/335M [00:02<00:01, 91.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  53% 262M/492M [00:02<00:02, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   7% 241M/3.44G [00:02<00:35, 90.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  69% 231M/335M [00:02<00:01, 85.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   7% 252M/3.44G [00:02<00:36, 88.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  72% 241M/335M [00:02<00:01, 83.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  58% 283M/492M [00:02<00:02, 97.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   8% 262M/3.44G [00:02<00:36, 86.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  75% 252M/335M [00:02<00:01, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   8% 273M/3.44G [00:03<00:38, 82.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  78% 262M/335M [00:05<00:05, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  62% 304M/492M [00:05<00:09, 19.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   8% 283M/3.44G [00:07<06:27, 8.14MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   9% 294M/3.44G [00:08<05:31, 9.48MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  81% 273M/335M [00:08<00:08, 7.69MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  64% 315M/492M [00:08<00:14, 12.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   9% 315M/3.44G [00:08<03:13, 16.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  91% 304M/335M [00:08<00:01, 16.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  68% 336M/492M [00:08<00:08, 17.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:   9% 325M/3.44G [00:08<02:34, 20.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  97% 325M/335M [00:08<00:00, 23.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  10% 336M/3.44G [00:08<02:02, 25.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)ch_model.safetensors: 100% 335M/335M [00:08<00:00, 39.0MB/s]\n",
            "\n",
            "Downloading (…)ch_model.safetensors:  10% 357M/3.44G [00:08<01:16, 40.2MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  77% 377M/492M [00:08<00:03, 33.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  11% 388M/3.44G [00:08<00:50, 60.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  83% 409M/492M [00:08<00:01, 46.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  12% 409M/3.44G [00:09<00:44, 68.1MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  87% 430M/492M [00:09<00:01, 53.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  13% 430M/3.44G [00:09<00:37, 81.2MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  92% 451M/492M [00:09<00:00, 65.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  13% 451M/3.44G [00:09<00:35, 85.3MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors:  96% 472M/492M [00:09<00:00, 77.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  14% 472M/3.44G [00:09<00:30, 98.9MB/s]\u001b[A\n",
            "\n",
            "Downloading model.safetensors: 100% 492M/492M [00:09<00:00, 89.2MB/s]\u001b[A\u001b[A\n",
            "Downloading model.safetensors: 100% 492M/492M [00:09<00:00, 50.7MB/s]\n",
            "Fetching 9 files:  56% 5/9 [00:10<00:08,  2.15s/it]\n",
            "Downloading (…)ch_model.safetensors:  15% 524M/3.44G [00:09<00:21, 138MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  16% 556M/3.44G [00:09<00:17, 165MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  17% 587M/3.44G [00:10<00:14, 191MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  18% 619M/3.44G [00:10<00:13, 209MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  19% 650M/3.44G [00:10<00:13, 209MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  20% 692M/3.44G [00:10<00:10, 254MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  21% 724M/3.44G [00:10<00:11, 237MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  22% 755M/3.44G [00:10<00:13, 206MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  23% 797M/3.44G [00:10<00:10, 247MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  24% 828M/3.44G [00:11<00:10, 247MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  25% 870M/3.44G [00:11<00:09, 268MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  26% 902M/3.44G [00:11<00:09, 257MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  27% 933M/3.44G [00:11<00:10, 249MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  28% 965M/3.44G [00:11<00:10, 245MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  29% 996M/3.44G [00:11<00:09, 253MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  30% 1.04G/3.44G [00:11<00:09, 252MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  31% 1.07G/3.44G [00:12<00:12, 195MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  32% 1.10G/3.44G [00:12<00:12, 193MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  33% 1.13G/3.44G [00:12<00:15, 151MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  34% 1.17G/3.44G [00:12<00:12, 186MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  35% 1.21G/3.44G [00:12<00:10, 208MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  36% 1.24G/3.44G [00:12<00:10, 219MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  37% 1.27G/3.44G [00:13<00:09, 220MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  38% 1.30G/3.44G [00:13<00:09, 230MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  39% 1.33G/3.44G [00:13<00:09, 232MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  40% 1.37G/3.44G [00:13<00:08, 234MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  41% 1.42G/3.44G [00:13<00:07, 266MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  42% 1.45G/3.44G [00:13<00:07, 265MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  43% 1.48G/3.44G [00:13<00:07, 252MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  44% 1.51G/3.44G [00:14<00:07, 253MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  45% 1.54G/3.44G [00:14<00:07, 240MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  46% 1.58G/3.44G [00:14<00:07, 258MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  47% 1.61G/3.44G [00:15<00:23, 77.8MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  48% 1.66G/3.44G [00:15<00:16, 108MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  50% 1.71G/3.44G [00:15<00:11, 153MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  51% 1.75G/3.44G [00:15<00:09, 183MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  52% 1.79G/3.44G [00:16<00:10, 155MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  53% 1.82G/3.44G [00:16<00:11, 138MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  54% 1.86G/3.44G [00:16<00:11, 136MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  55% 1.88G/3.44G [00:16<00:11, 141MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  55% 1.90G/3.44G [00:17<00:10, 146MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  56% 1.92G/3.44G [00:17<00:09, 152MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  57% 1.95G/3.44G [00:17<00:08, 168MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  57% 1.97G/3.44G [00:17<00:08, 169MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  59% 2.01G/3.44G [00:17<00:06, 215MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  60% 2.06G/3.44G [00:17<00:05, 254MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  61% 2.10G/3.44G [00:17<00:04, 291MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  62% 2.14G/3.44G [00:17<00:04, 269MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  63% 2.17G/3.44G [00:18<00:05, 215MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  64% 2.20G/3.44G [00:18<00:05, 230MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  65% 2.23G/3.44G [00:18<00:05, 220MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  66% 2.28G/3.44G [00:18<00:05, 230MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  67% 2.31G/3.44G [00:22<00:42, 26.9MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  68% 2.34G/3.44G [00:22<00:30, 36.1MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  69% 2.38G/3.44G [00:22<00:20, 52.7MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  70% 2.42G/3.44G [00:22<00:13, 73.3MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  71% 2.45G/3.44G [00:22<00:11, 88.9MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  72% 2.49G/3.44G [00:23<00:08, 107MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  73% 2.52G/3.44G [00:23<00:07, 128MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  74% 2.55G/3.44G [00:23<00:06, 136MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  75% 2.58G/3.44G [00:24<00:10, 81.3MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  76% 2.60G/3.44G [00:28<00:48, 17.3MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  77% 2.63G/3.44G [00:29<00:32, 24.5MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  77% 2.66G/3.44G [00:29<00:22, 34.2MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  79% 2.71G/3.44G [00:29<00:14, 51.9MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  80% 2.75G/3.44G [00:29<00:09, 73.7MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  81% 2.79G/3.44G [00:29<00:06, 100MB/s] \u001b[A\n",
            "Downloading (…)ch_model.safetensors:  82% 2.82G/3.44G [00:29<00:05, 121MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  83% 2.85G/3.44G [00:29<00:04, 144MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  84% 2.88G/3.44G [00:29<00:03, 159MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  85% 2.92G/3.44G [00:29<00:02, 178MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  86% 2.95G/3.44G [00:30<00:02, 192MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  87% 2.98G/3.44G [00:30<00:02, 211MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  88% 3.01G/3.44G [00:30<00:02, 214MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  89% 3.05G/3.44G [00:30<00:01, 234MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  90% 3.08G/3.44G [00:30<00:01, 224MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  91% 3.12G/3.44G [00:30<00:01, 252MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  92% 3.16G/3.44G [00:30<00:01, 242MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  93% 3.19G/3.44G [00:31<00:01, 238MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  94% 3.22G/3.44G [00:31<00:00, 251MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  95% 3.25G/3.44G [00:31<00:00, 236MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  95% 3.28G/3.44G [00:31<00:00, 251MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  96% 3.31G/3.44G [00:31<00:00, 264MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  97% 3.34G/3.44G [00:31<00:00, 251MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  98% 3.38G/3.44G [00:31<00:00, 249MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors:  99% 3.41G/3.44G [00:31<00:00, 249MB/s]\u001b[A\n",
            "Downloading (…)ch_model.safetensors: 100% 3.44G/3.44G [00:32<00:00, 107MB/s]\n",
            "Fetching 9 files: 100% 9/9 [00:32<00:00,  3.62s/it]\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "UNet2DConditionModel: 64, 8, 768, False, False\n",
            "U-Net converted to original U-Net\n",
            "Enable xformers for U-Net\n",
            "import network module: networks.lora\n",
            "[Dataset 0]\n",
            "caching latents.\n",
            "checking cache validity...\n",
            "100% 31/31 [00:00<00:00, 389291.69it/s]\n",
            "100% 31/31 [00:28<00:00,  1.07it/s]\n",
            "create LoRA network. base dim (rank): 16, alpha: 16.0\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "create LoRA for Text Encoder:\n",
            "create LoRA for Text Encoder: 72 modules.\n",
            "create LoRA for U-Net: 192 modules.\n",
            "enable LoRA for text encoder\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "use 8-bit AdamW optimizer | {}\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 31\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 31\n",
            "  num epochs / epoch数: 10\n",
            "  batch size per device / バッチサイズ: 1\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 310\n",
            "steps:   0% 0/310 [00:00<?, ?it/s]\n",
            "epoch 1/10\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:339: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
            "steps:  10% 31/310 [00:13<02:03,  2.25it/s, loss=0.0828]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000001.safetensors\n",
            "\n",
            "epoch 2/10\n",
            "steps:  20% 62/310 [00:25<01:41,  2.45it/s, loss=0.104]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000002.safetensors\n",
            "\n",
            "epoch 3/10\n",
            "steps:  30% 93/310 [00:37<01:26,  2.49it/s, loss=0.118]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000003.safetensors\n",
            "\n",
            "epoch 4/10\n",
            "steps:  40% 124/310 [00:49<01:14,  2.49it/s, loss=0.117]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000004.safetensors\n",
            "\n",
            "epoch 5/10\n",
            "steps:  50% 155/310 [01:02<01:02,  2.49it/s, loss=0.0807]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000005.safetensors\n",
            "\n",
            "epoch 6/10\n",
            "steps:  60% 186/310 [01:14<00:49,  2.50it/s, loss=0.1]   \n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000006.safetensors\n",
            "\n",
            "epoch 7/10\n",
            "steps:  70% 217/310 [01:26<00:37,  2.50it/s, loss=0.133]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000007.safetensors\n",
            "\n",
            "epoch 8/10\n",
            "steps:  80% 248/310 [01:39<00:24,  2.50it/s, loss=0.103] \n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000008.safetensors\n",
            "\n",
            "epoch 9/10\n",
            "steps:  90% 279/310 [01:51<00:12,  2.50it/s, loss=0.151]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last-000009.safetensors\n",
            "\n",
            "epoch 10/10\n",
            "steps: 100% 310/310 [02:04<00:00,  2.50it/s, loss=0.0968]\n",
            "saving checkpoint: /content/drive/MyDrive/Angelica/Logs/last.safetensors\n",
            "model saved.\n",
            "steps: 100% 310/310 [02:04<00:00,  2.49it/s, loss=0.0968]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "\u001b[30m╭─\u001b[0m\u001b[30m────────────────────\u001b[0m\u001b[30m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[30m \u001b[0m\u001b[30m─────────────────────\u001b[0m\u001b[30m─╮\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/gradio/\u001b[0m\u001b[1;33mblocks.py\u001b[0m:\u001b[94m2125\u001b[0m in             \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[92mblock_thread\u001b[0m                                                                 \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m2124 \u001b[0m            \u001b[94mwhile\u001b[0m \u001b[94mTrue\u001b[0m:                                               \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m2125                 time.sleep(\u001b[94m0.1\u001b[0m)                                       \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m2126 \u001b[0m        \u001b[94mexcept\u001b[0m (\u001b[96mKeyboardInterrupt\u001b[0m, \u001b[96mOSError\u001b[0m):                          \u001b[30m│\u001b[0m\n",
            "\u001b[30m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mKeyboardInterrupt\u001b[0m\n",
            "\n",
            "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
            "\n",
            "\u001b[30m╭─\u001b[0m\u001b[30m────────────────────\u001b[0m\u001b[30m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[30m \u001b[0m\u001b[30m─────────────────────\u001b[0m\u001b[30m─╮\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/content/kohya_ss/\u001b[0m\u001b[1;33mkohya_gui.py\u001b[0m:\u001b[94m133\u001b[0m in \u001b[92m<module>\u001b[0m                               \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m132 \u001b[0m                                                                       \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m133     UI(                                                                \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m134 \u001b[0m        username=args.username,                                        \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/content/kohya_ss/\u001b[0m\u001b[1;33mkohya_gui.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92mUI\u001b[0m                                      \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m 96 \u001b[0m        launch_kwargs[\u001b[33m'\u001b[0m\u001b[33mshare\u001b[0m\u001b[33m'\u001b[0m] = share                                 \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m 97     \u001b[1;4minterface.launch(**launch_kwargs)\u001b[0m                                  \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m 98 \u001b[0m                                                                       \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/gradio/\u001b[0m\u001b[1;33mblocks.py\u001b[0m:\u001b[94m2041\u001b[0m in \u001b[92mlaunch\u001b[0m      \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m2040 \u001b[0m        \u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m prevent_thread_lock \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m is_in_interactive_mode:    \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m2041             \u001b[1;4;96mself\u001b[0m\u001b[1;4m.block_thread()\u001b[0m                                       \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m2042 \u001b[0m                                                                      \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/gradio/\u001b[0m\u001b[1;33mblocks.py\u001b[0m:\u001b[94m2129\u001b[0m in             \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[92mblock_thread\u001b[0m                                                                 \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m2128 \u001b[0m            \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.server:                                           \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m2129                 \u001b[1;4;96mself\u001b[0m\u001b[1;4m.server.close()\u001b[0m                                   \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m2130 \u001b[0m            \u001b[94mfor\u001b[0m tunnel \u001b[95min\u001b[0m CURRENT_TUNNELS:                            \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/gradio/\u001b[0m\u001b[1;33mnetworking.py\u001b[0m:\u001b[94m49\u001b[0m in \u001b[92mclose\u001b[0m     \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m 48 \u001b[0m        \u001b[96mself\u001b[0m.should_exit = \u001b[94mTrue\u001b[0m                                        \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m 49         \u001b[1;4;96mself\u001b[0m\u001b[1;4m.thread.join()\u001b[0m                                             \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m 50 \u001b[0m                                                                       \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/usr/lib/python3.11/\u001b[0m\u001b[1;33mthreading.py\u001b[0m:\u001b[94m1119\u001b[0m in \u001b[92mjoin\u001b[0m                                \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m1118 \u001b[0m        \u001b[94mif\u001b[0m timeout \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                           \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m1119             \u001b[1;4;96mself\u001b[0m\u001b[1;4m._wait_for_tstate_lock()\u001b[0m                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m1120 \u001b[0m        \u001b[94melse\u001b[0m:                                                         \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[2;33m/usr/lib/python3.11/\u001b[0m\u001b[1;33mthreading.py\u001b[0m:\u001b[94m1139\u001b[0m in \u001b[92m_wait_for_tstate_lock\u001b[0m               \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m1138 \u001b[0m        \u001b[94mtry\u001b[0m:                                                          \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m1139             \u001b[94mif\u001b[0m lock.acquire(block, timeout):                          \u001b[30m│\u001b[0m\n",
            "\u001b[30m│\u001b[0m   \u001b[2m1140 \u001b[0m                lock.release()                                        \u001b[30m│\u001b[0m\n",
            "\u001b[30m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mKeyboardInterrupt\u001b[0m\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b86fdf4e570a28a54b.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#@title Train with Kohya's Stable Diffusion Trainers\n",
        "%cd /content\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install dadaptation==3.1 diffusers[torch]==0.17.1 easygui==0.98.3 einops==0.6.0 fairscale==0.4.13 ftfy==6.1.1 gradio==3.36.1\n",
        "!pip install lion-pytorch==0.0.6 lycoris_lora==1.8.0.dev6 open-clip-torch==2.20.0 prodigyopt==1.0 pytorch-lightning==1.9.0 safetensors==0.3.1 timm==0.6.12\n",
        "!pip install tk==0.1.0 transformers==4.30.2 --no-deps voluptuous==0.13.1 wandb==0.15.0 xformers==0.0.20 omegaconf\n",
        "!pip install torchvision==0.15.2 huggingface_hub==0.16.4 accelerate==0.21.0 numpy==1.24.4 timm==0.6.13 --force-reinstall\n",
        "!pip uninstall -y jax jaxlib flax optax orbax\n",
        "\n",
        "\n",
        "%cd /content\n",
        "#!git clone -b 0.41.0 https://github.com/TimDettmers/bitsandbytes\n",
        "#%cd /content/bitsandbytes\n",
        "#!CUDA_VERSION=118 make cuda11x\n",
        "#!python setup.py install\n",
        "\n",
        "!pip install bitsandbytes==0.41.1 --prefer-binary --no-cache-dir\n",
        "\n",
        "\n",
        "%cd /content\n",
        "!git clone -b v1.0 https://github.com/camenduru/kohya_ss\n",
        "%cd /content/kohya_ss\n",
        "\n",
        "!python kohya_gui.py --share --headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "kbdXX1xudYCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stable-diffusion-webui/models/Lora\n",
        "!cp /content/drive/MyDrive/Angelica/Logs/last.safetensors /content/stable-diffusion-webui/models/Lora/Angelica-LoRA.safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj5MEGkwSc3-",
        "outputId": "856d81de-2ce4-4d2e-cfd0-cef5e84f9a16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/stable-diffusion-webui/models/Lora/Angelica-LoRA.safetensors': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone AUTOMATIC1111 repo\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui /content/stable-diffusion-webui\n",
        "\n",
        "# Go into the repo\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "# Skip downloading the base model (we only need LoRA testing)\n",
        "!sed -i -e 's@\\\"sd_model_checkpoint\\\":.*@\\\"sd_model_checkpoint\\\": \\\"\\\",@' /content/stable-diffusion-webui/config.json\n",
        "\n",
        "# Launch the web UI with no model (we'll load LoRA manually)\n",
        "!COMMANDLINE_ARGS=\"--share --disable-safe-unpickle --no-half-vae\" REQS_FILE=\"requirements_versions.txt\" python launch.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBYOZlXrSmJ1",
        "outputId": "4cf680c0-1dc9-46e0-e376-39e160248d60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 34968, done.\u001b[K\n",
            "remote: Total 34968 (delta 0), reused 0 (delta 0), pack-reused 34968 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34968/34968), 35.58 MiB | 15.35 MiB/s, done.\n",
            "Resolving deltas: 100% (24421/24421), done.\n",
            "/content/stable-diffusion-webui\n",
            "sed: can't read /content/stable-diffusion-webui/config.json: No such file or directory\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Version: v1.10.1\n",
            "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
            "Installing clip\n",
            "Cloning assets into /content/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 132.70 KiB | 33.17 MiB/s, done.\n",
            "Cloning Stable Diffusion into /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...\n",
            "remote: Enumerating objects: 586, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 586 (delta 1), reused 0 (delta 0), pack-reused 580 (from 4)\u001b[K\n",
            "Receiving objects: 100% (586/586), 73.45 MiB | 14.27 MiB/s, done.\n",
            "Resolving deltas: 100% (282/282), done.\n",
            "Cloning Stable Diffusion XL into /content/stable-diffusion-webui/repositories/generative-models...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/generative-models'...\n",
            "remote: Enumerating objects: 1108, done.\u001b[K\n",
            "remote: Counting objects: 100% (504/504), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 1108 (delta 397), reused 359 (delta 359), pack-reused 604 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1108/1108), 86.65 MiB | 14.01 MiB/s, done.\n",
            "Resolving deltas: 100% (579/579), done.\n",
            "Cloning K-diffusion into /content/stable-diffusion-webui/repositories/k-diffusion...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/k-diffusion'...\n",
            "remote: Enumerating objects: 1350, done.\u001b[K\n",
            "remote: Counting objects: 100% (1350/1350), done.\u001b[K\n",
            "remote: Compressing objects: 100% (444/444), done.\u001b[K\n",
            "remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1350/1350), 233.36 KiB | 19.45 MiB/s, done.\n",
            "Resolving deltas: 100% (951/951), done.\n",
            "Cloning BLIP into /content/stable-diffusion-webui/repositories/BLIP...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.04 MiB | 23.54 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Installing requirements\n",
            "Launching Web UI with arguments: --share --disable-safe-unpickle --no-half-vae\n",
            "2025-07-14 18:57:01.779577: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752519421.986564   60840 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752519422.045782   60840 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-14 18:57:02.499037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/launch.py\", line 48, in <module>\n",
            "    main()\n",
            "  File \"/content/stable-diffusion-webui/launch.py\", line 44, in main\n",
            "    start()\n",
            "  File \"/content/stable-diffusion-webui/modules/launch_utils.py\", line 465, in start\n",
            "    import webui\n",
            "  File \"/content/stable-diffusion-webui/webui.py\", line 13, in <module>\n",
            "    initialize.imports()\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize.py\", line 26, in imports\n",
            "    from modules import paths, timer, import_hook, errors  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui/modules/paths.py\", line 60, in <module>\n",
            "    import sgm  # noqa: F401\n",
            "    ^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/__init__.py\", line 1, in <module>\n",
            "    from .models import AutoencodingEngine, DiffusionEngine\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/models/__init__.py\", line 1, in <module>\n",
            "    from .autoencoder import AutoencodingEngine\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/models/autoencoder.py\", line 12, in <module>\n",
            "    from ..modules.diffusionmodules.model import Decoder, Encoder\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/modules/__init__.py\", line 1, in <module>\n",
            "    from .encoders.modules import GeneralConditioner\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/modules/encoders/modules.py\", line 7, in <module>\n",
            "    import open_clip\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/open_clip/__init__.py\", line 1, in <module>\n",
            "    from .coca_model import CoCa\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/open_clip/coca_model.py\", line 15, in <module>\n",
            "    from .model import CLIPTextCfg, CLIPVisionCfg, _build_vision_tower, _build_text_tower\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/open_clip/model.py\", line 18, in <module>\n",
            "    from .timm_model import TimmModel\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/open_clip/timm_model.py\", line 12, in <module>\n",
            "    import timm\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/__init__.py\", line 2, in <module>\n",
            "    from .models import create_model, list_models, is_model, list_modules, model_entrypoint, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/models/__init__.py\", line 28, in <module>\n",
            "    from .maxxvit import *\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/models/maxxvit.py\", line 225, in <module>\n",
            "    @dataclass\n",
            "     ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/dataclasses.py\", line 1232, in dataclass\n",
            "    return wrap(cls)\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/dataclasses.py\", line 1222, in wrap\n",
            "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/dataclasses.py\", line 958, in _process_class\n",
            "    cls_fields.append(_get_field(cls, name, type, kw_only))\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/dataclasses.py\", line 815, in _get_field\n",
            "    raise ValueError(f'mutable default {type(f.default)} for field '\n",
            "ValueError: mutable default <class 'timm.models.maxxvit.MaxxVitConvCfg'> for field conv_cfg is not allowed: use default_factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downgrade timm to a version that works with AUTOMATIC1111 and open_clip\n",
        "!pip install timm==0.6.13 --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YbU-NHIbSwEb",
        "outputId": "1baa5933-db52-43ae-84e8-f3926b7aac50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==0.6.13\n",
            "  Downloading timm-0.6.13-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting torch>=1.7 (from timm==0.6.13)\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision (from timm==0.6.13)\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pyyaml (from timm==0.6.13)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub (from timm==0.6.13)\n",
            "  Using cached huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filelock (from torch>=1.7->timm==0.6.13)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch>=1.7->timm==0.6.13)\n",
            "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.7->timm==0.6.13)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.7->timm==0.6.13)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=1.7->timm==0.6.13)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch>=1.7->timm==0.6.13)\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch>=1.7->timm==0.6.13)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting setuptools>=40.8.0 (from triton==3.3.1->torch>=1.7->timm==0.6.13)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting packaging>=20.9 (from huggingface-hub->timm==0.6.13)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting requests (from huggingface-hub->timm==0.6.13)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tqdm>=4.42.1 (from huggingface-hub->timm==0.6.13)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub->timm==0.6.13)\n",
            "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting numpy (from torchvision->timm==0.6.13)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->timm==0.6.13)\n",
            "  Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.7->timm==0.6.13)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.7->timm==0.6.13)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub->timm==0.6.13)\n",
            "  Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->huggingface-hub->timm==0.6.13)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub->timm==0.6.13)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->huggingface-hub->timm==0.6.13)\n",
            "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, urllib3, typing-extensions, tqdm, sympy, setuptools, pyyaml, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, huggingface-hub, torch, torchvision, timm\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.14.1\n",
            "    Uninstalling typing_extensions-4.14.1:\n",
            "      Successfully uninstalled typing_extensions-4.14.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 69.5.1\n",
            "    Uninstalling setuptools-69.5.1:\n",
            "      Successfully uninstalled setuptools-69.5.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.5.0\n",
            "    Uninstalling Pillow-9.5.0:\n",
            "      Successfully uninstalled Pillow-9.5.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.2\n",
            "    Uninstalling numpy-1.26.2:\n",
            "      Successfully uninstalled numpy-1.26.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: hf-xet\n",
            "    Found existing installation: hf-xet 1.1.5\n",
            "    Uninstalling hf-xet-1.1.5:\n",
            "      Successfully uninstalled hf-xet-1.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.1\n",
            "    Uninstalling fsspec-2025.5.1:\n",
            "      Successfully uninstalled fsspec-2025.5.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.7.14\n",
            "    Uninstalling certifi-2025.7.14:\n",
            "      Successfully uninstalled certifi-2025.7.14\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.16.4\n",
            "    Uninstalling huggingface-hub-0.16.4:\n",
            "      Successfully uninstalled huggingface-hub-0.16.4\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2\n",
            "    Uninstalling torchvision-0.15.2:\n",
            "      Successfully uninstalled torchvision-0.15.2\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 0.6.12\n",
            "    Uninstalling timm-0.6.12:\n",
            "      Successfully uninstalled timm-0.6.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires flax>=0.2.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires jaxlib>=0.1.51, which is not installed.\n",
            "orbax-checkpoint 0.11.16 requires jax>=0.5.0, which is not installed.\n",
            "chex 0.1.89 requires jax>=0.4.27, which is not installed.\n",
            "chex 0.1.89 requires jaxlib>=0.4.27, which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "blendmodes 2022 requires numpy<2,>=1.22.1, but you have numpy 2.3.1 which is incompatible.\n",
            "blendmodes 2022 requires Pillow<10,>=9.0.0, but you have pillow 11.3.0 which is incompatible.\n",
            "gradio 3.41.2 requires markupsafe~=2.0, but you have markupsafe 3.0.2 which is incompatible.\n",
            "gradio 3.41.2 requires numpy~=1.0, but you have numpy 2.3.1 which is incompatible.\n",
            "gradio 3.41.2 requires pillow<11.0,>=8.0, but you have pillow 11.3.0 which is incompatible.\n",
            "xformers 0.0.20 requires torch==2.0.1, but you have torch 2.7.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.1 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "thinc 8.3.6 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.24.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.102.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "langchain-core 0.3.68 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "langchain-core 0.3.68 requires pydantic>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\n",
            "google-genai 1.24.0 requires anyio<5.0.0,>=4.8.0, but you have anyio 3.7.1 which is incompatible.\n",
            "google-genai 1.24.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.24.1 which is incompatible.\n",
            "google-genai 1.24.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.22 which is incompatible.\n",
            "google-genai 1.24.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "dataproc-spark-connect 0.8.2 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.25.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.18.3 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 1.10.22 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.0 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\n",
            "google-cloud-spanner 3.55.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.21.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "langchain 0.3.26 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2025.7.14 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.4 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-2.3.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 packaging-25.0 pillow-11.3.0 pyyaml-6.0.2 requests-2.32.4 setuptools-80.9.0 sympy-1.14.0 timm-0.6.13 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 triton-3.3.1 typing-extensions-4.14.1 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "numpy",
                  "packaging",
                  "pkg_resources"
                ]
              },
              "id": "b83a39d6d58e4ec595dfb0f286cae32a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-enter the AUTOMATIC1111 directory just to be safe\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "# Relaunch with the same arguments\n",
        "!COMMANDLINE_ARGS=\"--share --disable-safe-unpickle --no-half-vae\" REQS_FILE=\"requirements_versions.txt\" python launch.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy23uIynWDg0",
        "outputId": "93c38866-6b33-4134-d43a-f8fed55b6f88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui\n",
            "Python 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Version: v1.10.1\n",
            "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
            "Installing requirements\n",
            "Launching Web UI with arguments: --share --disable-safe-unpickle --no-half-vae\n",
            "False\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            "\n",
            "  warn(msg)\n",
            "================================================================================\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//mp.kaggle.net')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('8013'), PosixPath('http')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-1vwhhqt719z --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true ')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('https'), PosixPath('//github.com/kravipa1/cakechat/blob/master/kohya_ss_colab.ipynb')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "DEBUG: Possible options found for libcudart.so: {PosixPath('/usr/local/cuda/lib64/libcudart.so')}\n",
            "CUDA SETUP: PyTorch settings found: CUDA_VERSION=126, Highest Compute Capability: 7.5.\n",
            "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
            "CUDA SETUP: Required library version not found: libbitsandbytes_cuda126.so. Maybe you need to compile it from source?\n",
            "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
            "\n",
            "================================================ERROR=====================================\n",
            "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
            "1. You need to manually override the PyTorch CUDA version. Please see: \"https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
            "2. CUDA driver not installed\n",
            "3. CUDA not installed\n",
            "4. You have multiple conflicting CUDA libraries\n",
            "5. Required library not pre-compiled for this bitsandbytes release!\n",
            "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
            "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
            "================================================================================\n",
            "\n",
            "CUDA SETUP: Something unexpected happened. Please compile from source:\n",
            "git clone https://github.com/TimDettmers/bitsandbytes.git\n",
            "cd bitsandbytes\n",
            "CUDA_VERSION=126\n",
            "python setup.py install\n",
            "CUDA SETUP: Setup Failed!\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/launch.py\", line 48, in <module>\n",
            "    main()\n",
            "  File \"/content/stable-diffusion-webui/launch.py\", line 44, in main\n",
            "    start()\n",
            "  File \"/content/stable-diffusion-webui/modules/launch_utils.py\", line 465, in start\n",
            "    import webui\n",
            "  File \"/content/stable-diffusion-webui/webui.py\", line 13, in <module>\n",
            "    initialize.imports()\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize.py\", line 26, in imports\n",
            "    from modules import paths, timer, import_hook, errors  # noqa: F401\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui/modules/paths.py\", line 60, in <module>\n",
            "    import sgm  # noqa: F401\n",
            "    ^^^^^^^^^^\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/__init__.py\", line 1, in <module>\n",
            "    from .models import AutoencodingEngine, DiffusionEngine\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/models/__init__.py\", line 1, in <module>\n",
            "    from .autoencoder import AutoencodingEngine\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/models/autoencoder.py\", line 12, in <module>\n",
            "    from ..modules.diffusionmodules.model import Decoder, Encoder\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/modules/__init__.py\", line 1, in <module>\n",
            "    from .encoders.modules import GeneralConditioner\n",
            "  File \"/content/stable-diffusion-webui/repositories/generative-models/sgm/modules/encoders/modules.py\", line 5, in <module>\n",
            "    import kornia\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kornia/__init__.py\", line 11, in <module>\n",
            "    from . import augmentation, color, contrib, core, enhance, feature, io, losses, metrics, morphology, tracking, utils, x\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kornia/x/__init__.py\", line 2, in <module>\n",
            "    from .trainer import Trainer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kornia/x/trainer.py\", line 11, in <module>\n",
            "    from accelerate import Accelerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/__init__.py\", line 3, in <module>\n",
            "    from .accelerator import Accelerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 35, in <module>\n",
            "    from .checkpointing import load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/checkpointing.py\", line 24, in <module>\n",
            "    from .utils import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/__init__.py\", line 131, in <module>\n",
            "    from .bnb import has_4bit_bnb_layers, load_and_quantize_model\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/bnb.py\", line 42, in <module>\n",
            "    import bitsandbytes as bnb\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/__init__.py\", line 6, in <module>\n",
            "    from . import cuda_setup, utils, research\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/research/__init__.py\", line 1, in <module>\n",
            "    from . import nn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/research/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import LinearFP8Mixed, LinearFP8Global\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/research/nn/modules.py\", line 8, in <module>\n",
            "    from bitsandbytes.optim import GlobalOptimManager\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/optim/__init__.py\", line 6, in <module>\n",
            "    from bitsandbytes.cextension import COMPILED_WITH_CUDA\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py\", line 20, in <module>\n",
            "    raise RuntimeError('''\n",
            "RuntimeError: \n",
            "        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n",
            "\n",
            "        python -m bitsandbytes\n",
            "\n",
            "        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
            "        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
            "        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rLl_m3zWEis",
        "outputId": "a7b8255e-9fdb-44a7-f00a-f4e92ee76a65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧼 CLEAN EVERYTHING\n",
        "!rm -rf /content/stable-diffusion-webui\n",
        "\n",
        "# 🔁 Clone a fresh AUTOMATIC1111 repo\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui /content/stable-diffusion-webui\n",
        "!cd /content/stable-diffusion-webui\n",
        "\n",
        "# 📦 Install minimal dependencies needed (NO bitsandbytes, no extra junk)\n",
        "!pip install torch torchvision torchaudio xformers --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# 📁 Make LoRA folder and copy your trained file\n",
        "!mkdir -p /content/stable-diffusion-webui/models/Lora\n",
        "!cp \"/content/drive/MyDrive/Angelica/Output/last.safetensors\" \"/content/stable-diffusion-webui/models/Lora/Angelica-LoRA.safetensors\"\n",
        "\n",
        "# 🚀 Launch with clean config\n",
        "!COMMANDLINE_ARGS=\"--share --disable-safe-unpickle --no-half-vae\" python launch.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld3dcULWXnP9",
        "outputId": "24a5a561-f0a3-439f-bfa1-0c1a2f9e01a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 34968, done.\u001b[K\n",
            "remote: Total 34968 (delta 0), reused 0 (delta 0), pack-reused 34968 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34968/34968), 35.54 MiB | 15.73 MiB/s, done.\n",
            "Resolving deltas: 100% (24409/24409), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (69.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (9.5.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pyre-extensions==0.0.29 in /usr/local/lib/python3.11/dist-packages (from xformers) (0.0.29)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers\n",
            "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, torchaudio\n",
            "  Attempting uninstall: xformers\n",
            "    Found existing installation: xformers 0.0.20\n",
            "    Uninstalling xformers-0.0.20:\n",
            "      Successfully uninstalled xformers-0.0.20\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed torchaudio-2.7.1+cu118 xformers-0.0.31.post1\n",
            "cp: cannot stat '/content/drive/MyDrive/Angelica/Output/last.safetensors': No such file or directory\n",
            "python3: can't open file '/content/launch.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HpWqPwroXqFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}